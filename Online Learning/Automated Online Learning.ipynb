{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Section 1\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "data = pandas.read_csv(input('Enter the filename of the dataset to use for training:'))\n",
    "\n",
    "if vars().__contains__('mod_dec'):\n",
    "    pass\n",
    "else:\n",
    "    output = input('Enter the name of the column containing the target attribute:')\n",
    "    d_size = len(data[output])\n",
    "    adj_acc_base = data[output].nunique()\n",
    "\n",
    "if vars().__contains__('mod_dec'):\n",
    "    pass\n",
    "else:\n",
    "    column_number = 0\n",
    "    categorical_cols = []\n",
    "    numerical_cols = []\n",
    "    for column_type in data.dtypes:\n",
    "        if column_type == object and data.columns[column_number] != output:\n",
    "            categorical_cols.append(column_number)\n",
    "        elif data.columns[column_number] != output:\n",
    "            numerical_cols.append(column_number)\n",
    "        column_number += 1         \n",
    "    \n",
    "data_categorical = data[data.columns[categorical_cols]]\n",
    "data_numerical = data[data.columns[numerical_cols]]\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    if vars().__contains__('mod_dec'):\n",
    "        pass\n",
    "    else:\n",
    "        number_unique = data_categorical.nunique()\n",
    "        col_num = 0\n",
    "        low_nuniq_cols = []\n",
    "        for col_nuniq in number_unique:\n",
    "            if col_nuniq <= 20:\n",
    "                low_nuniq_cols.append(col_num)\n",
    "            col_num +=1\n",
    "\n",
    "    data_categorical = data_categorical[data_categorical.columns[low_nuniq_cols]]\n",
    "    data_categorical = data_categorical.fillna('None')    \n",
    "    \n",
    "    if vars().__contains__('mod_dec'):\n",
    "        encoder = OneHotEncoder(categories = enc_cat, sparse = False, handle_unknown = 'ignore')\n",
    "        encoder = encoder.fit_transform(data_categorical)\n",
    "    else:\n",
    "        encoder = OneHotEncoder(sparse = False)\n",
    "        encoder = encoder.fit(data_categorical)\n",
    "        enc_cat = encoder.categories_\n",
    "        encoder = encoder.transform(data_categorical)\n",
    "        \n",
    "    data_categorical = pandas.DataFrame(encoder)\n",
    "\n",
    "if len(numerical_cols) > 0:\n",
    "    scaler = StandardScaler().fit(data_numerical)\n",
    "    data_numerical = pandas.DataFrame(scaler.transform(data_numerical))\n",
    "    data_numerical = data_numerical.fillna(0) \n",
    "\n",
    "data = data_categorical.join(other = data_numerical.join(data[output]), rsuffix = 'n')\n",
    "\n",
    "############################# Section 2\n",
    "\n",
    "if vars().__contains__('mod_dec'):\n",
    "    if mod_dec == 'dynamic':\n",
    "        rest = data\n",
    "        rest_input = rest.drop(output, axis=1)\n",
    "        rest_output = rest[output]\n",
    "        \n",
    "        exec(open('dynamic weighted majority.py').read())\n",
    "    else:\n",
    "        test_ensemble = data\n",
    "        test_ensemble_input = test_ensemble.drop(output, axis=1)\n",
    "        test_ensemble_output = test_ensemble[output]\n",
    "        \n",
    "        exec(open('weighted majority.py').read())\n",
    "        \n",
    "############################# Section 3\n",
    "\n",
    "else:\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    n_features = len(data.columns)\n",
    "    n_rows = len(data[data.columns[0]])\n",
    "    number_categories = len(data_categorical.columns)\n",
    "\n",
    "    if len(categorical_cols) > 0:\n",
    "        ratio_num_cat = len(numerical_cols) / len(categorical_cols)\n",
    "    else:\n",
    "        ratio_num_cat = 'NA'\n",
    "\n",
    "    if len(numerical_cols) > 0:\n",
    "        mean_of_skew = ((data_numerical.mean() - data_numerical.median()) / data_numerical.std()).mean()\n",
    "        std_of_skew = ((data_numerical.mean() - data_numerical.median()) / data_numerical.std()).std()\n",
    "    else:\n",
    "        mean_of_skew = 'NA'\n",
    "        std_of_skew = 'NA'\n",
    "    \n",
    "    metadata = [n_features, n_rows, number_categories, ratio_num_cat, mean_of_skew, std_of_skew] \n",
    "    all_metadata = pandas.read_csv('all metadata.csv')\n",
    "    all_metadata_input = all_metadata.drop(['Best model'], axis = 1)\n",
    "    all_metadata_output = all_metadata['Best model']\n",
    "    \n",
    "    norm = MinMaxScaler()\n",
    "    norm.fit(all_metadata_input)\n",
    "    transf_inp = norm.transform(all_metadata_input)\n",
    "    transf_met = norm.transform(numpy.reshape(metadata, [1, -1]))\n",
    "    \n",
    "    mod_select = KNeighborsClassifier(n_neighbors = 1)\n",
    "    mod_select.fit(transf_inp, all_metadata_output)\n",
    "    mod_chosen = mod_select.predict(transf_met)\n",
    "    \n",
    "############################# Section 4.1   \n",
    "    \n",
    "    if mod_chosen == 'DWM':\n",
    "        mod_dec = 'dynamic'\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        \n",
    "        if d_size >= 1000:\n",
    "            tr_size = 500\n",
    "        else:\n",
    "            tr_size = d_size / 2\n",
    "        \n",
    "        train, rest = train_test_split(data, train_size = tr_size, shuffle = False)\n",
    "        train_input = train.drop(output, axis=1)\n",
    "        train_output = train[output]\n",
    "        rest_input = rest.drop(output, axis=1)\n",
    "        rest_output = rest[output]\n",
    "\n",
    "        all_models = {'model_1' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_2' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_3' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_4' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_5' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_6' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_7' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_8' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_9' : [DecisionTreeClassifier(), 'U'],\n",
    "                      'model_10' : [DecisionTreeClassifier(), 'U']}\n",
    "\n",
    "        all_models['model_1'][0].fit(train_input, train_output)\n",
    "        all_models['model_1'][1] = 'T'\n",
    "\n",
    "############################# Section 4.2        \n",
    "        \n",
    "        def dynamic(new_input, new_output, prior_correct_predictions, prior_incorrect_predictions, \n",
    "                    prior_number_pred, p_weight_m1, p_weight_m2, p_weight_m3, p_weight_m4, p_weight_m5, \n",
    "                    p_weight_m6, p_weight_m7, p_weight_m8, p_weight_m9, p_weight_m10):\n",
    "\n",
    "            global number_pred, correct_predictions, incorrect_predictions, weight_m1, weight_m2, weight_m3\n",
    "            global weight_m4, weight_m5, weight_m6, weight_m7, weight_m8, weight_m9, weight_m10\n",
    "\n",
    "            if all_models['model_1'][1] == 'T': \n",
    "                pred_model_1 = all_models['model_1'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_1 = None           \n",
    "            if all_models['model_2'][1] == 'T': \n",
    "                pred_model_2 = all_models['model_2'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_2 = None\n",
    "            if all_models['model_3'][1] == 'T': \n",
    "                pred_model_3 = all_models['model_3'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_3 = None\n",
    "            if all_models['model_4'][1] == 'T': \n",
    "                pred_model_4 = all_models['model_4'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_4 = None\n",
    "            if all_models['model_5'][1] == 'T': \n",
    "                pred_model_5 = all_models['model_5'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_5 = None\n",
    "            if all_models['model_6'][1] == 'T': \n",
    "                pred_model_6 = all_models['model_6'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_6 = None\n",
    "            if all_models['model_7'][1] == 'T': \n",
    "                pred_model_7 = all_models['model_7'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_7 = None\n",
    "            if all_models['model_8'][1] == 'T': \n",
    "                pred_model_8 = all_models['model_8'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_8 = None\n",
    "            if all_models['model_9'][1] == 'T': \n",
    "                pred_model_9 = all_models['model_9'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_9 = None\n",
    "            if all_models['model_10'][1] == 'T': \n",
    "                pred_model_10 = all_models['model_10'][0].predict(new_input)\n",
    "            else:\n",
    "                pred_model_10 = None\n",
    "\n",
    "            uniq_preds = {}\n",
    "            all_preds = [[pred_model_1, weight_m1], [pred_model_2, weight_m2], [pred_model_3, weight_m3],\n",
    "                         [pred_model_4, weight_m4], [pred_model_5, weight_m5], [pred_model_6, weight_m6], \n",
    "                         [pred_model_7, weight_m7], [pred_model_8, weight_m8], [pred_model_9, weight_m9],\n",
    "                         [pred_model_10, weight_m10]]\n",
    "\n",
    "            for m in all_preds:\n",
    "                if m[0] != None:\n",
    "                    if m[0][0] not in uniq_preds:\n",
    "                        uniq_preds.update({m[0][0]:m[1]})\n",
    "                    else:\n",
    "                        uniq_preds.update({m[0][0]:(uniq_preds[m[0][0]] + m[1])})\n",
    "\n",
    "            ensemble_pred = max(uniq_preds, key = lambda d:uniq_preds[d])\n",
    "            \n",
    "############################# Section 4.3            \n",
    "\n",
    "            if new_output != 'unknown':   \n",
    "                number_pred = prior_number_pred + 1\n",
    "\n",
    "                if ensemble_pred == new_output:\n",
    "                    correct_predictions = prior_correct_predictions + 1\n",
    "                else:\n",
    "                    incorrect_predictions = prior_incorrect_predictions + 1\n",
    "                    wrong_pred_input.append(new_input)\n",
    "                    wrong_pred_output.append(new_output)\n",
    "\n",
    "                if pred_model_1 != new_output:\n",
    "                    if pred_model_1 != None:\n",
    "                        if weight_m1 >= 0.001: \n",
    "                            weight_m1 = p_weight_m1 - 0.0005\n",
    "                elif weight_m1 < 5:\n",
    "                    weight_m1 = p_weight_m1 + 0.0005\n",
    "                if pred_model_2 != new_output:\n",
    "                    if pred_model_2 != None:\n",
    "                        weight_m2 = p_weight_m2 - 0.0005\n",
    "                elif weight_m2 < 5:\n",
    "                    weight_m2 = p_weight_m2 + 0.0005\n",
    "                if pred_model_3 != new_output:\n",
    "                    if pred_model_3 != None:\n",
    "                        weight_m3 = p_weight_m3 - 0.0005\n",
    "                elif weight_m3 < 5:\n",
    "                    weight_m3 = p_weight_m3 + 0.0005  \n",
    "                if pred_model_4 != new_output:\n",
    "                    if pred_model_4 != None:\n",
    "                        weight_m4 = p_weight_m4 - 0.0005\n",
    "                elif weight_m4 < 5:\n",
    "                    weight_m4 = p_weight_m4 + 0.0005\n",
    "                if pred_model_5 != new_output:\n",
    "                    if pred_model_5 != None:\n",
    "                        weight_m5 = p_weight_m5 - 0.0005\n",
    "                elif weight_m5 < 5:\n",
    "                    weight_m5 = p_weight_m5 + 0.0005\n",
    "                if pred_model_6 != new_output:\n",
    "                    if pred_model_6 != None:\n",
    "                        weight_m6 = p_weight_m6 - 0.0005\n",
    "                elif weight_m6 < 5:\n",
    "                    weight_m6 = p_weight_m6 + 0.0005\n",
    "                if pred_model_7 != new_output:\n",
    "                    if pred_model_7 != None:\n",
    "                        weight_m7 = p_weight_m7 - 0.0005\n",
    "                elif weight_m7 < 5:\n",
    "                    weight_m7 = p_weight_m7 + 0.0005\n",
    "                if pred_model_8 != new_output:\n",
    "                    if pred_model_8 != None:\n",
    "                        weight_m8 = p_weight_m8 - 0.0005\n",
    "                elif weight_m8 < 5:\n",
    "                    weight_m8 = p_weight_m8 + 0.0005\n",
    "                if pred_model_9 != new_output:\n",
    "                    if pred_model_9 != None:\n",
    "                        weight_m9 = p_weight_m9 - 0.0005\n",
    "                elif weight_m9 < 5:\n",
    "                    weight_m9 = p_weight_m9 + 0.0005\n",
    "                if pred_model_10 != new_output:\n",
    "                    if pred_model_10 != None:\n",
    "                        weight_m10 = p_weight_m10 - 0.0005\n",
    "                elif weight_m10 < 5:\n",
    "                    weight_m10 = p_weight_m10 + 0.0005\n",
    "            else:\n",
    "                blind_predictions.append(ensemble_pred)\n",
    "\n",
    "        correct_predictions = 0\n",
    "        incorrect_predictions = 0\n",
    "        weight_m1 = 1\n",
    "        weight_m2 = 1\n",
    "        weight_m3 = 1\n",
    "        weight_m4 = 1\n",
    "        weight_m5 = 1\n",
    "        weight_m6 = 1\n",
    "        weight_m7 = 1\n",
    "        weight_m8 = 1\n",
    "        weight_m9 = 1\n",
    "        weight_m10 = 1\n",
    "        \n",
    "        exec(open('dynamic weighted majority.py').read())\n",
    "        \n",
    "############################# Section 5.1        \n",
    "        \n",
    "    else:\n",
    "        mod_dec = 'weighted'\n",
    "        \n",
    "        import numpy\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        from sklearn import svm\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        train, test = train_test_split(data, test_size = 0.3)\n",
    "        test_models, test_ensemble = train_test_split(test, test_size = 0.5)\n",
    "        train_input = train.drop(output, axis=1)\n",
    "        train_output = train[output]\n",
    "        test_models_input = test_models.drop(output, axis=1)\n",
    "        test_models_output = test_models[output]\n",
    "        test_ensemble_input = test_ensemble.drop(output, axis=1)\n",
    "        test_ensemble_output = test_ensemble[output]\n",
    "\n",
    "        grid_tree = {'min_samples_split':[2, 3, 4, 5]}\n",
    "        initial_tree = DecisionTreeClassifier()\n",
    "        optimiser_tree = GridSearchCV(initial_tree, grid_tree, cv = 3)\n",
    "        optimiser_tree.fit(train_input, train_output)\n",
    "        model_tree = optimiser_tree.best_estimator_\n",
    "        predictions_tree = model_tree.predict(test_models_input)\n",
    "        accuracy_tree = accuracy_score(test_models_output, predictions_tree)\n",
    "\n",
    "        grid_knn = {'n_neighbors':[3, 5, 7, 9], 'metric':['euclidean','manhattan']}\n",
    "        initial_knn = KNeighborsClassifier()\n",
    "        optimiser_knn = GridSearchCV(initial_knn, grid_knn, cv = 3)\n",
    "        optimiser_knn.fit(train_input, train_output)\n",
    "        model_knn = optimiser_knn.best_estimator_\n",
    "        predictions_knn = model_knn.predict(test_models_input)\n",
    "        accuracy_knn = accuracy_score(test_models_output, predictions_knn)\n",
    "\n",
    "        grid_nb = {'var_smoothing':[0.75e-9, 1e-9, 1.25e-9]}\n",
    "        initial_nb = GaussianNB()\n",
    "        optimiser_nb = GridSearchCV(initial_nb, grid_nb, cv = 3)\n",
    "        optimiser_nb.fit(train_input, train_output)\n",
    "        model_nb = optimiser_nb.best_estimator_\n",
    "        predictions_nb = model_nb.predict(test_models_input)\n",
    "        accuracy_nb = accuracy_score(test_models_output, predictions_nb)\n",
    "\n",
    "        model_svm = svm.SVC(gamma = 'auto')\n",
    "        model_svm.fit(train_input, train_output)\n",
    "        predictions_svm = model_svm.predict(test_models_input)\n",
    "        accuracy_svm = accuracy_score(test_models_output, predictions_svm)\n",
    "\n",
    "        grid_nn = {'hidden_layer_sizes':[(5), (10), (15)]}\n",
    "        initial_nn = MLPClassifier(max_iter = 500, random_state = 1)\n",
    "        optimiser_nn = GridSearchCV(initial_nn, grid_nn, cv = 3)\n",
    "        optimiser_nn.fit(train_input, train_output)\n",
    "        model_nn = optimiser_nn.best_estimator_\n",
    "        predictions_nn = model_nn.predict(test_models_input)\n",
    "        accuracy_nn = accuracy_score(test_models_output, predictions_nn)\n",
    "\n",
    "        scores = [{'model':model_tree, 'accuracy':accuracy_tree}, {'model':model_knn, 'accuracy':accuracy_knn},\n",
    "                  {'model':model_nb, 'accuracy':accuracy_nb}, {'model':model_svm, 'accuracy':accuracy_svm}, \n",
    "                  {'model':model_nn, 'accuracy':accuracy_nn}]\n",
    "\n",
    "        scores_sorted = sorted(scores, key = lambda d:d['accuracy'], reverse = True)\n",
    "\n",
    "        first_model = scores_sorted[0]['model']\n",
    "        second_model = scores_sorted[1]['model']\n",
    "        third_model = scores_sorted[2]['model']\n",
    "\n",
    "############################# Section 5.2        \n",
    "        \n",
    "        def online(new_data_input, new_data_output, prior_weight_fm, prior_weight_sm, prior_weight_tm,\n",
    "                   prior_correct_predictions, prior_incorrect_predictions):\n",
    "\n",
    "            global weight_fm, weight_sm, weight_tm, correct_predictions, \\\n",
    "                   incorrect_predictions, whole_ensemble_prediction\n",
    "\n",
    "            ensemble_prediction_fm = first_model.predict(new_data_input)\n",
    "            ensemble_prediction_sm = second_model.predict(new_data_input)\n",
    "            ensemble_prediction_tm = third_model.predict(new_data_input)\n",
    "\n",
    "            if ensemble_prediction_fm == ensemble_prediction_sm == ensemble_prediction_tm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_fm\n",
    "            elif ensemble_prediction_fm == ensemble_prediction_sm:\n",
    "                if weight_fm + weight_sm >= weight_tm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_fm\n",
    "                else:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_tm\n",
    "            elif ensemble_prediction_fm == ensemble_prediction_tm:\n",
    "                if weight_fm + weight_tm >= weight_sm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_fm\n",
    "                else:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_sm\n",
    "            elif ensemble_prediction_sm == ensemble_prediction_tm:\n",
    "                if weight_sm + weight_tm >= weight_fm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_sm\n",
    "                else:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_fm\n",
    "            else:\n",
    "                if weight_fm > weight_sm and weight_fm > weight_tm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_fm\n",
    "                elif weight_sm > weight_fm and weight_sm > weight_tm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_sm\n",
    "                elif weight_tm > weight_fm and weight_tm > weight_sm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_tm\n",
    "                elif weight_fm == weight_sm == weight_tm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_fm\n",
    "                elif weight_fm == weight_sm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_fm\n",
    "                elif weight_fm == weight_tm:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_fm\n",
    "                else:\n",
    "                    whole_ensemble_prediction = ensemble_prediction_sm\n",
    "                    \n",
    "############################# Section 5.3                    \n",
    "\n",
    "            if new_data_output != 'unknown':            \n",
    "                if ensemble_prediction_fm != new_data_output:\n",
    "                    weight_fm = prior_weight_fm * 0.999\n",
    "                if ensemble_prediction_sm != new_data_output:\n",
    "                    weight_sm = prior_weight_sm * 0.999\n",
    "                if ensemble_prediction_tm != new_data_output:\n",
    "                    weight_tm = prior_weight_tm * 0.999\n",
    "                if weight_fm >= weight_sm and weight_fm >= weight_tm:\n",
    "                    weight_sm = weight_sm / weight_fm\n",
    "                    weight_tm = weight_tm / weight_fm\n",
    "                    weight_fm = weight_fm / weight_fm\n",
    "                elif weight_sm >= weight_tm:\n",
    "                    weight_fm = weight_fm / weight_sm\n",
    "                    weight_tm = weight_tm / weight_sm\n",
    "                    weight_sm = weight_sm / weight_sm\n",
    "                else:\n",
    "                    weight_fm = weight_fm / weight_tm\n",
    "                    weight_sm = weight_sm / weight_tm\n",
    "                    weight_tm = weight_tm / weight_tm\n",
    "                if whole_ensemble_prediction == new_data_output:\n",
    "                    correct_predictions = prior_correct_predictions + 1\n",
    "                else:\n",
    "                    incorrect_predictions = prior_incorrect_predictions + 1\n",
    "            else:\n",
    "                blind_predictions.append(whole_ensemble_prediction)\n",
    "\n",
    "        weight_fm = 1\n",
    "        weight_sm = 1\n",
    "        weight_tm = 1\n",
    "        correct_predictions = 0\n",
    "        incorrect_predictions = 0\n",
    "            \n",
    "        exec(open('weighted majority.py').read())\n",
    "        \n",
    "############################# N.B. Sections 6 & 7 are located in the files named \n",
    "############################# 'dynamic weighted majority.py' and 'weighted majority.py' respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Section 8\n",
    "\n",
    "prediction_data = pandas.read_csv(input('Enter the filename of the dataset to be predicted:'))\n",
    "pred_cat = prediction_data[prediction_data.columns[categorical_cols]]\n",
    "pred_num = prediction_data[prediction_data.columns[numerical_cols]]\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    pred_cat = pred_cat[pred_cat.columns[low_nuniq_cols]]\n",
    "    pred_cat = pred_cat.fillna('None')\n",
    "    pred_enc = OneHotEncoder(categories = enc_cat, sparse = False, handle_unknown = 'ignore')\n",
    "    pred_enc = pred_enc.fit_transform(pred_cat)\n",
    "    pred_cat = pandas.DataFrame(pred_enc)\n",
    "    \n",
    "if len(numerical_cols) > 0:\n",
    "    pred_num = pandas.DataFrame(scaler.transform(pred_num))\n",
    "    pred_num = pred_num.fillna(0)\n",
    "\n",
    "prediction_data_mod = pred_cat.join(other = pred_num.join(prediction_data[output]), rsuffix = 'n')\n",
    "pred_dat_input = prediction_data_mod.drop(output, axis = 1)\n",
    "pred_dat_output = prediction_data_mod[output]\n",
    "blind_predictions = []\n",
    "\n",
    "############################# Section 9\n",
    "\n",
    "if mod_dec == 'dynamic':\n",
    "    for stream_in, stream_out in zip(numpy.array(pred_dat_input), numpy.array(pred_dat_output)):\n",
    "\n",
    "        dynamic(numpy.reshape(stream_in, [1, -1]), stream_out, correct_predictions, incorrect_predictions,\n",
    "                number_pred, weight_m1, weight_m2, weight_m3, weight_m4, weight_m5, weight_m6, weight_m7, \n",
    "                weight_m8, weight_m9, weight_m10)\n",
    "\n",
    "    print('The chosen algorithm is Dynamic Weighted Majority')\n",
    "    print('The accuracy of the ensemble is', round(accuracy_ensemble, 2))\n",
    "    print('The adjusted accuracy of the ensemble is', round(adj_accuracy_ensemble, 2))\n",
    "\n",
    "    if all_models['model_1'][1] == 'T':\n",
    "        print('The weight of model 1 is', round(weight_m1, 3))\n",
    "    if all_models['model_2'][1] == 'T':\n",
    "        print('The weight of model 2 is', round(weight_m2, 3))\n",
    "    if all_models['model_3'][1] == 'T':\n",
    "        print('The weight of model 3 is', round(weight_m3, 3))\n",
    "    if all_models['model_4'][1] == 'T':\n",
    "        print('The weight of model 4 is', round(weight_m4, 3))\n",
    "    if all_models['model_5'][1] == 'T':\n",
    "        print('The weight of model 5 is', round(weight_m5, 3))\n",
    "    if all_models['model_6'][1] == 'T':\n",
    "        print('The weight of model 6 is', round(weight_m6, 3))\n",
    "    if all_models['model_7'][1] == 'T':\n",
    "        print('The weight of model 7 is', round(weight_m7, 3))\n",
    "    if all_models['model_8'][1] == 'T':\n",
    "        print('The weight of model 8 is', round(weight_m8, 3))\n",
    "    if all_models['model_9'][1] == 'T':\n",
    "        print('The weight of model 9 is', round(weight_m9, 3))\n",
    "    if all_models['model_10'][1] == 'T':\n",
    "        print('The weight of model 10 is', round(weight_m10, 3))\n",
    "else:\n",
    "    for stream_input, stream_output in zip(numpy.array(pred_dat_input), numpy.array(pred_dat_output)):\n",
    "        \n",
    "        online(numpy.reshape(stream_input, [1, -1]), stream_output, weight_fm, weight_sm, weight_tm,\n",
    "               correct_predictions, incorrect_predictions)\n",
    "\n",
    "    print('The chosen algorithm is Weighted Majority')\n",
    "    print('The first model is', first_model, 'and has a weight of', round(weight_fm, 2))\n",
    "    print('The second model is', second_model, 'and has a weight of', round(weight_sm, 2))\n",
    "    print('The third model is', third_model, 'and has a weight of', round(weight_tm, 2))\n",
    "    print('The accuracy of the ensemble is', round(accuracy_ensemble, 2))   \n",
    "    print('The adjusted accuracy of the ensemble is', round(adj_accuracy_ensemble, 2))\n",
    "        \n",
    "if pred_dat_output[0] == 'unknown':\n",
    "    unknown_predictions = pandas.DataFrame(blind_predictions, columns = ['Prediction'])\n",
    "    prediction_input = prediction_data.drop(output, axis = 1)\n",
    "    full_pred = prediction_input.join(unknown_predictions)\n",
    "\n",
    "print(full_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
